---
title: HYPER-V 上的系統資源成本 |Microsoft Docs
ms.custom: ''
ms.date: 06/08/2017
ms.prod: biztalk-server
ms.reviewer: ''
ms.suite: ''
ms.tgt_pltfrm: ''
ms.topic: article
ms.assetid: 9f25a76c-1c41-41c0-b28d-d7473dbe1cd1
caps.latest.revision: 8
author: MandiOhlinger
ms.author: mandia
manager: anneta
ms.openlocfilehash: 768b34b6b1a51768f1c0070c961749e1975015f9
ms.sourcegitcommit: 53b16fe6c1b1707ecf233dbd05f780653eb19419
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 11/01/2018
ms.locfileid: "50753054"
---
# <a name="system-resource-costs-on-hyper-v"></a><span data-ttu-id="63c10-102">HYPER-V 上的系統資源成本</span><span class="sxs-lookup"><span data-stu-id="63c10-102">System Resource Costs on Hyper-V</span></span>
## <a name="system-resource-costs-associated-with-running-a-guest-operating-system-on-hyper-v"></a><span data-ttu-id="63c10-103">相關聯之 HYPER-V 上執行客體作業系統的系統資源成本</span><span class="sxs-lookup"><span data-stu-id="63c10-103">System Resource Costs Associated with Running a Guest Operating System on Hyper-V</span></span>  
 <span data-ttu-id="63c10-104">伺服器虛擬化軟體，沒有與執行才能支援在 HYPER-V 上執行的客體作業系統的虛擬化程式碼相關聯的額外負荷量。</span><span class="sxs-lookup"><span data-stu-id="63c10-104">As with any server virtualization software, there is a certain amount of overhead associated with running the virtualization code required to support guest operating systems running on Hyper-V.</span></span> <span data-ttu-id="63c10-105">下列清單摘要說明在 HYPER-V 虛擬機器上執行的客體作業系統時，與特定資源相關聯的額外負荷：</span><span class="sxs-lookup"><span data-stu-id="63c10-105">The following list summarizes the overhead associated with specific resources when running guest operating systems on Hyper-V virtual machines:</span></span>  
  
### <a name="cpu-overhead"></a><span data-ttu-id="63c10-106">CPU 額外負荷</span><span class="sxs-lookup"><span data-stu-id="63c10-106">CPU Overhead</span></span>  
 <span data-ttu-id="63c10-107">9 與 12%之間的範圍內找不到相關的額外負荷的 HYPER-V 虛擬機器中執行來賓作業系統 CPU。</span><span class="sxs-lookup"><span data-stu-id="63c10-107">The CPU overhead associated with running a guest operating system in a Hyper-V virtual machine was found to range between 9 and 12%.</span></span>  <span data-ttu-id="63c10-108">例如，通常在 HYPER-V 虛擬機器上執行客體作業系統必須可用 88 91%的 CPU 資源可用來在實體硬體上執行相等的作業系統。</span><span class="sxs-lookup"><span data-stu-id="63c10-108">For example, a guest operating system running on a Hyper-V virtual machine typically had available 88-91% of the CPU resources available to an equivalent operating system running on physical hardware.</span></span>  
  
### <a name="memory-overhead"></a><span data-ttu-id="63c10-109">記憶體額外負荷</span><span class="sxs-lookup"><span data-stu-id="63c10-109">Memory Overhead</span></span>  
 <span data-ttu-id="63c10-110">對於 HYPER-V 主機電腦中，相關聯的 HYPER-V 虛擬機器上執行客體作業系統的記憶體成本發現是大約 300 MB 的 hypervisor，加上 32MB 的第一個 GB 的 RAM 配置給每部虛擬機器，加上另一個 8 MB針對每個額外 GB 的 RAM 配置給每個虛擬機器。</span><span class="sxs-lookup"><span data-stu-id="63c10-110">For the Hyper-V host computer, the memory cost associated with running a guest operating system on a Hyper-V virtual machine was observed to be approximately 300 MB for the hypervisor, plus 32 MB for the first GB of RAM allocated to each virtual machine, plus another 8 MB for every additional GB of RAM allocated to each virtual machine.</span></span> <span data-ttu-id="63c10-111">如需有關如何在 HYPER-V 虛擬機器上執行的客體作業系統的記憶體配置方式的詳細資訊，請參閱中的 < 最佳化記憶體效能 > 一節[檢查清單： 在 HYPER-V 上的 最佳化效能](~/technical-guides/checklist-optimizing-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="63c10-111">For more information about allocating memory to guest operating systems running on a Hyper-V virtual machine, see the “Optimizing Memory Performance” section in [Checklist: Optimizing Performance on Hyper-V](~/technical-guides/checklist-optimizing-performance-on-hyper-v.md).</span></span>  
  
### <a name="network-overhead"></a><span data-ttu-id="63c10-112">網路額外負荷</span><span class="sxs-lookup"><span data-stu-id="63c10-112">Network Overhead</span></span>  
 <span data-ttu-id="63c10-113">直接能歸因於執行客體作業系統的 HYPER-V 虛擬機器中觀察到的網路延遲是小於 1 毫秒和客體作業系統通常維護的網路輸出佇列長度小於 1。</span><span class="sxs-lookup"><span data-stu-id="63c10-113">Network latency directly attributable to running a guest operating system in a Hyper-V virtual machine was observed to be less than 1 ms and the guest operating system typically maintained a network output queue length of less than one.</span></span> <span data-ttu-id="63c10-114">如需有關測量網路輸出佇列長度的詳細資訊，請參閱中的 < 測量網路效能 > 一節[檢查清單： 測量 HYPER-V 上的效能](../technical-guides/checklist-measuring-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="63c10-114">For more information about measuring the network output queue length, see the “Measuring Network Performance” section in [Checklist: Measuring Performance on Hyper-V](../technical-guides/checklist-measuring-performance-on-hyper-v.md).</span></span>  
  
### <a name="disk-overhead"></a><span data-ttu-id="63c10-115">磁碟的額外負荷</span><span class="sxs-lookup"><span data-stu-id="63c10-115">Disk Overhead</span></span>  
 <span data-ttu-id="63c10-116">在 HYPER-V 中使用 「 穿通磁碟 」 功能，當找不到磁碟與 HYPER-V 虛擬機器中執行為客體作業系統相關聯的 I/O 額外負荷介於 6 到 8%之間的範圍。</span><span class="sxs-lookup"><span data-stu-id="63c10-116">When using the passthrough disk feature in Hyper-V, disk I/O overhead associated with running a guest operating system in a Hyper-V virtual machine was found to range between 6 and 8 %.</span></span> <span data-ttu-id="63c10-117">比方說，通常在 HYPER-V 上執行客體作業系統會有可用的 92 94%的磁碟 I/O 可測量的效能評定工具 IOMeter 的開放原始碼磁碟效能的實體硬體上執行對等作業系統。</span><span class="sxs-lookup"><span data-stu-id="63c10-117">For example, a guest operating system running on Hyper-V typically had available 92-94% of the disk I/O available to an equivalent operating system running on physical hardware as measured by the open source disk performance benchmarking tool IOMeter.</span></span>  
  
 <span data-ttu-id="63c10-118">如需測量 HYPER-V 主機或客體作業系統上使用 「 效能監視器的磁碟延遲資訊，請參閱中的 < 測量磁碟 I/O 效能 > 一節[檢查清單： 測量 HYPER-V 上的效能](../technical-guides/checklist-measuring-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="63c10-118">For information about measuring disk latency on a Hyper-V host or guest operating system using Performance Monitor, see the “Measuring Disk I/O Performance” section in [Checklist: Measuring Performance on Hyper-V](../technical-guides/checklist-measuring-performance-on-hyper-v.md).</span></span>  
  
 <span data-ttu-id="63c10-119">本節的其餘部分會提供 BizTalk Server 上的磁碟效能的背景資訊、 說明測試組態參數使用，並提供取得測試結果的摘要。</span><span class="sxs-lookup"><span data-stu-id="63c10-119">The remainder of this section provides background information on BizTalk Server disk performance, describes the test configuration parameters used, and provides a summary of test results obtained.</span></span>  
  
#### <a name="disk-performance-when-running-a-biztalk-server-solution-on-hyper-v"></a><span data-ttu-id="63c10-120">HYPER-V 上執行 BizTalk Server 解決方案時的磁碟效能</span><span class="sxs-lookup"><span data-stu-id="63c10-120">Disk Performance When Running a BizTalk Server Solution on Hyper-V</span></span>  
 <span data-ttu-id="63c10-121">BizTalk Server 是非常資料庫密集應用程式可能需要建立的 SQL Server 中的達 13 個資料庫。</span><span class="sxs-lookup"><span data-stu-id="63c10-121">BizTalk Server is an extremely database intensive application that may require the creation of up to 13 databases in SQL Server.</span></span> <span data-ttu-id="63c10-122">BizTalk Server 將資料保存到磁碟以絕佳的頻率，然後此外，這麼做為 MSDTC 交易的內容中。</span><span class="sxs-lookup"><span data-stu-id="63c10-122">BizTalk Server persists data to disk with great frequency and furthermore, does so within the context of an MSDTC transaction.</span></span> <span data-ttu-id="63c10-123">因此，資料庫效能是任何 BizTalk Server 解決方案的整體效能最重要的。</span><span class="sxs-lookup"><span data-stu-id="63c10-123">Therefore, database performance is paramount to the overall performance of any BizTalk Server solution.</span></span> <span data-ttu-id="63c10-124">HYPER-V 提供綜合 SCSI 控制器，而這兩者提供效能優勢明顯優於在模擬的 IDE 裝置這類 IDE 篩選器驅動程式隨附了 Virtual Server 2005。</span><span class="sxs-lookup"><span data-stu-id="63c10-124">Hyper-V provides a synthetic SCSI controller and an IDE filter driver which both provide significant performance benefits over using an emulated IDE device such as is provided with Virtual Server 2005.</span></span>  
  
 <span data-ttu-id="63c10-125">設定為使用 SCSI 控制站的資料磁碟區的磁碟。</span><span class="sxs-lookup"><span data-stu-id="63c10-125">Configure disks for data volumes using the SCSI controller.</span></span> <span data-ttu-id="63c10-126">這樣會保證會安裝整合服務，因為如果而模擬的 IDE 控制器是可用，而不需要安裝 HYPER-V 整合服務，已安裝 HYPER-V 整合服務，可以只安裝 SCSI 控制器。</span><span class="sxs-lookup"><span data-stu-id="63c10-126">This will guarantee that the integration services are installed because the SCSI controller can only be installed if Hyper-V integration services are installed whereas the emulated IDE controller is available without installing Hyper-V integration services.</span></span> <span data-ttu-id="63c10-127">使用 SCSI 控制站或 integration services 提供 IDE 篩選器驅動程式執行的磁碟 I/O 是遠優於磁碟 I/O 效能提供模擬的 IDE 控制器。</span><span class="sxs-lookup"><span data-stu-id="63c10-127">Disk I/O performed using either the SCSI controller or the IDE filter driver provided with integration services is significantly better than disk I/O performance provided with the emulated IDE controller.</span></span> <span data-ttu-id="63c10-128">因此，若要確保最佳的磁碟 I/O 效能，如 HYPER-V 虛擬化環境中的資料檔案，在主機和客體作業系統上安裝 integration services，而且與綜合 SCSI 控制站設定為資料磁碟區的磁碟。</span><span class="sxs-lookup"><span data-stu-id="63c10-128">Therefore, to ensure optimal disk I/O performance for the data files in a Hyper-V virtualized environment, install integration services on both the host and guest operating system and configure disks for data volumes with the synthetic SCSI controller.</span></span> <span data-ttu-id="63c10-129">對於跨越多個資料磁碟機的極大量的儲存體 I/O 工作負載，每個 VHD 應該附加至個別的綜合 SCSI 控制器以提升整體效能。</span><span class="sxs-lookup"><span data-stu-id="63c10-129">For highly intensive storage I/O workloads that span multiple data drives, each VHD should be attached to a separate synthetic SCSI controller for better overall performance.</span></span> <span data-ttu-id="63c10-130">此外，每個 VHD 應該儲存在個別的實體磁碟或 Lun 上。</span><span class="sxs-lookup"><span data-stu-id="63c10-130">In addition, each VHD should be stored on separate physical disks or LUNs.</span></span>  
  
#### <a name="measuring-passthrough-disk-performance"></a><span data-ttu-id="63c10-131">測量的傳遞磁碟效能</span><span class="sxs-lookup"><span data-stu-id="63c10-131">Measuring PassThrough Disk Performance</span></span>  
 <span data-ttu-id="63c10-132">在練習中任何彙總期間請務必充分使用可用的資源。</span><span class="sxs-lookup"><span data-stu-id="63c10-132">During any consolidation exercise it is important to make maximum use of available resources.</span></span> <span data-ttu-id="63c10-133">如先前所述，SQL 資料磁碟區上的儲存體 I/O 會在 BizTalk Server 解決方案的整體效能中扮演重要的部分。</span><span class="sxs-lookup"><span data-stu-id="63c10-133">As discussed previously, storage I/O on SQL data volumes plays a significant part in the overall performance of a BizTalk Server solution.</span></span> <span data-ttu-id="63c10-134">因此在本指南中，已通過測試的實體磁碟效能的傳遞磁碟，在 HYPER-V 中的相對效能。</span><span class="sxs-lookup"><span data-stu-id="63c10-134">Therefore as part of this guidance, the relative performance of a physical disk to the performance of a passthrough disk in Hyper-V was tested.</span></span> <span data-ttu-id="63c10-135">Physical_SQL01 中的相對效能的 MessageBox 資料磁碟機和 Virtual_SQL01 使用測量的 IOMeter 開放原始碼工具原本由 Intel Corporation 發展，現在維護的開放原始檔開發實驗室 (OSDL)。</span><span class="sxs-lookup"><span data-stu-id="63c10-135">The relative performance of the MessageBox data drive in Physical_SQL01 and Virtual_SQL01 was measured using the IOMeter open source tool originally developed by Intel Corporation and now maintained by the open Source Development Lab (OSDL).</span></span> <span data-ttu-id="63c10-136">如需 IOMeter 的詳細資訊，請參閱[ http://go.microsoft.com/fwlink/?LinkId=122412 ](http://go.microsoft.com/fwlink/?LinkId=122412)。</span><span class="sxs-lookup"><span data-stu-id="63c10-136">For more information about IOMeter, see [http://go.microsoft.com/fwlink/?LinkId=122412](http://go.microsoft.com/fwlink/?LinkId=122412).</span></span>  
  
 <span data-ttu-id="63c10-137">下表描述的實體和虛擬的硬體組態來在測試環境、 所使用的 IOMeter 設定選項、 執行、 測試的描述，以及結果的摘要。</span><span class="sxs-lookup"><span data-stu-id="63c10-137">The following tables describe the physical and virtual hardware configuration used in the test environment, the IOMeter configuration options that were used, a description of the test that was run, and a summary of results.</span></span>  
  
#### <a name="configuration-used-for-testing"></a><span data-ttu-id="63c10-138">用於測試的組態</span><span class="sxs-lookup"><span data-stu-id="63c10-138">Configuration Used for Testing</span></span>  
  
### <a name="physicalsql01"></a><span data-ttu-id="63c10-139">Physical_SQL01</span><span class="sxs-lookup"><span data-stu-id="63c10-139">Physical_SQL01</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="63c10-140">**型號**</span><span class="sxs-lookup"><span data-stu-id="63c10-140">**Model**</span></span>|<span data-ttu-id="63c10-141">HP DL580</span><span class="sxs-lookup"><span data-stu-id="63c10-141">HP DL580</span></span>|  
|<span data-ttu-id="63c10-142">**處理器**</span><span class="sxs-lookup"><span data-stu-id="63c10-142">**Processor**</span></span>|<span data-ttu-id="63c10-143">四個處理器，四核心 Intel Xeon 2.4 Ghz</span><span class="sxs-lookup"><span data-stu-id="63c10-143">Quad processor, Quad-core Intel Xeon 2.4Ghz</span></span>|  
|<span data-ttu-id="63c10-144">**記憶體**</span><span class="sxs-lookup"><span data-stu-id="63c10-144">**Memory**</span></span>|<span data-ttu-id="63c10-145">8 GB</span><span class="sxs-lookup"><span data-stu-id="63c10-145">8 GB</span></span>|  
|<span data-ttu-id="63c10-146">**網路功能**</span><span class="sxs-lookup"><span data-stu-id="63c10-146">**Networking**</span></span>|<span data-ttu-id="63c10-147">HP NC3T3i 多功能 Gigabit Server 配接器</span><span class="sxs-lookup"><span data-stu-id="63c10-147">HP NC3T3i Multifunction Gigabit Server adapter</span></span>|  
|<span data-ttu-id="63c10-148">**SAN 組態**</span><span class="sxs-lookup"><span data-stu-id="63c10-148">**SAN configuration**</span></span>|<span data-ttu-id="63c10-149">直接連接 SAN 存放裝置 （請參閱下表）</span><span class="sxs-lookup"><span data-stu-id="63c10-149">Direct attached SAN storage (see table below)</span></span>|  
  
### <a name="physicalsql01--san-configuration"></a><span data-ttu-id="63c10-150">Physical_SQL01 – SAN 組態</span><span class="sxs-lookup"><span data-stu-id="63c10-150">Physical_SQL01 – SAN Configuration</span></span>  
  
|<span data-ttu-id="63c10-151">磁碟機代號</span><span class="sxs-lookup"><span data-stu-id="63c10-151">Drive letter</span></span>|<span data-ttu-id="63c10-152">描述</span><span class="sxs-lookup"><span data-stu-id="63c10-152">Description</span></span>|<span data-ttu-id="63c10-153">LUN 大小</span><span class="sxs-lookup"><span data-stu-id="63c10-153">LUN Size</span></span>|<span data-ttu-id="63c10-154">RAID 設定</span><span class="sxs-lookup"><span data-stu-id="63c10-154">RAID configuration</span></span>|  
|------------------|-----------------|--------------|------------------------|  
|<span data-ttu-id="63c10-155">G:</span><span class="sxs-lookup"><span data-stu-id="63c10-155">G:</span></span>|<span data-ttu-id="63c10-156">Data_Sys</span><span class="sxs-lookup"><span data-stu-id="63c10-156">Data_Sys</span></span>|<span data-ttu-id="63c10-157">10</span><span class="sxs-lookup"><span data-stu-id="63c10-157">10</span></span>|<span data-ttu-id="63c10-158">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-158">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-159">H:</span><span class="sxs-lookup"><span data-stu-id="63c10-159">H:</span></span>|<span data-ttu-id="63c10-160">Logs_Sys</span><span class="sxs-lookup"><span data-stu-id="63c10-160">Logs_Sys</span></span>|<span data-ttu-id="63c10-161">10</span><span class="sxs-lookup"><span data-stu-id="63c10-161">10</span></span>|<span data-ttu-id="63c10-162">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-162">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-163">I:</span><span class="sxs-lookup"><span data-stu-id="63c10-163">I:</span></span>|<span data-ttu-id="63c10-164">Data_TempDb</span><span class="sxs-lookup"><span data-stu-id="63c10-164">Data_TempDb</span></span>|<span data-ttu-id="63c10-165">50</span><span class="sxs-lookup"><span data-stu-id="63c10-165">50</span></span>|<span data-ttu-id="63c10-166">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-166">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-167">J:</span><span class="sxs-lookup"><span data-stu-id="63c10-167">J:</span></span>|<span data-ttu-id="63c10-168">Logs_TempDb</span><span class="sxs-lookup"><span data-stu-id="63c10-168">Logs_TempDb</span></span>|<span data-ttu-id="63c10-169">50</span><span class="sxs-lookup"><span data-stu-id="63c10-169">50</span></span>|<span data-ttu-id="63c10-170">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-170">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-171">K:</span><span class="sxs-lookup"><span data-stu-id="63c10-171">K:</span></span>|<span data-ttu-id="63c10-172">Data_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="63c10-172">Data_BtsMsgBox</span></span>|<span data-ttu-id="63c10-173">300</span><span class="sxs-lookup"><span data-stu-id="63c10-173">300</span></span>|<span data-ttu-id="63c10-174">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-174">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-175">L:</span><span class="sxs-lookup"><span data-stu-id="63c10-175">L:</span></span>|<span data-ttu-id="63c10-176">Logs_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="63c10-176">Logs_BtsMsgBox</span></span>|<span data-ttu-id="63c10-177">100</span><span class="sxs-lookup"><span data-stu-id="63c10-177">100</span></span>|<span data-ttu-id="63c10-178">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-178">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-179">M:</span><span class="sxs-lookup"><span data-stu-id="63c10-179">M:</span></span>|<span data-ttu-id="63c10-180">MSDTC</span><span class="sxs-lookup"><span data-stu-id="63c10-180">MSDTC</span></span>|<span data-ttu-id="63c10-181">5</span><span class="sxs-lookup"><span data-stu-id="63c10-181">5</span></span>|<span data-ttu-id="63c10-182">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-182">RAID 0 + 1</span></span>|  
  
### <a name="hyper-vhostsql01"></a><span data-ttu-id="63c10-183">Hyper-V_Host_SQL01</span><span class="sxs-lookup"><span data-stu-id="63c10-183">Hyper-V_Host_SQL01</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="63c10-184">**型號**</span><span class="sxs-lookup"><span data-stu-id="63c10-184">**Model**</span></span>|<span data-ttu-id="63c10-185">HP DL580</span><span class="sxs-lookup"><span data-stu-id="63c10-185">HP DL580</span></span>|  
|<span data-ttu-id="63c10-186">**處理器**</span><span class="sxs-lookup"><span data-stu-id="63c10-186">**Processor**</span></span>|<span data-ttu-id="63c10-187">四個處理器，四核心 Intel Xeon 2.4 Ghz</span><span class="sxs-lookup"><span data-stu-id="63c10-187">Quad processor, Quad-core Intel Xeon 2.4Ghz</span></span>|  
|<span data-ttu-id="63c10-188">**記憶體**</span><span class="sxs-lookup"><span data-stu-id="63c10-188">**Memory**</span></span>|<span data-ttu-id="63c10-189">32 GB</span><span class="sxs-lookup"><span data-stu-id="63c10-189">32 GB</span></span>|  
|<span data-ttu-id="63c10-190">**網路功能**</span><span class="sxs-lookup"><span data-stu-id="63c10-190">**Networking**</span></span>|<span data-ttu-id="63c10-191">Broadcom BCM5708C NetXtreme II GigEHP DL380 第 5 代</span><span class="sxs-lookup"><span data-stu-id="63c10-191">Broadcom BCM5708C NetXtreme II GigEHP DL380 G5</span></span>|  
  
### <a name="virtualsql01---virtual-machine-configuration"></a><span data-ttu-id="63c10-192">Virtual_SQL01-虛擬機器組態</span><span class="sxs-lookup"><span data-stu-id="63c10-192">Virtual_SQL01 - Virtual Machine Configuration</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="63c10-193">**虛擬處理器**</span><span class="sxs-lookup"><span data-stu-id="63c10-193">**Virtual processors**</span></span>|<span data-ttu-id="63c10-194">配置 4</span><span class="sxs-lookup"><span data-stu-id="63c10-194">4 allocated</span></span>|  
|<span data-ttu-id="63c10-195">**記憶體**</span><span class="sxs-lookup"><span data-stu-id="63c10-195">**Memory**</span></span>|<span data-ttu-id="63c10-196">8 GB</span><span class="sxs-lookup"><span data-stu-id="63c10-196">8 GB</span></span>|  
|<span data-ttu-id="63c10-197">**網路功能**</span><span class="sxs-lookup"><span data-stu-id="63c10-197">**Networking**</span></span>|<span data-ttu-id="63c10-198">虛擬機器的網路連線到：</span><span class="sxs-lookup"><span data-stu-id="63c10-198">Virtual Machine Networking connected to:</span></span><br /><span data-ttu-id="63c10-199">Broadcom BCM5708C NetXtreme II GigE</span><span class="sxs-lookup"><span data-stu-id="63c10-199">Broadcom BCM5708C NetXtreme II GigE</span></span>|  
|<span data-ttu-id="63c10-200">**硬碟設定**</span><span class="sxs-lookup"><span data-stu-id="63c10-200">**Hard disk configuration**</span></span>|<span data-ttu-id="63c10-201">**IDE 控制器**– 30 GB，作業系統固定 vhd</span><span class="sxs-lookup"><span data-stu-id="63c10-201">**IDE controller** – 30 GB fixed vhd for Operating System</span></span><br /><span data-ttu-id="63c10-202">**SCSI 控制器**-7 直接連接 （請參閱下表） 的傳遞 SAN Lun</span><span class="sxs-lookup"><span data-stu-id="63c10-202">**SCSI controller** - 7 directly attached passthrough SAN LUNs (see table below)</span></span>|  
  
### <a name="virtualsql01--san-configuration"></a><span data-ttu-id="63c10-203">Virtual_SQL01 – SAN 組態</span><span class="sxs-lookup"><span data-stu-id="63c10-203">Virtual_SQL01 – SAN Configuration</span></span>  
  
|<span data-ttu-id="63c10-204">磁碟機代號</span><span class="sxs-lookup"><span data-stu-id="63c10-204">Drive letter</span></span>|<span data-ttu-id="63c10-205">描述</span><span class="sxs-lookup"><span data-stu-id="63c10-205">Description</span></span>|<span data-ttu-id="63c10-206">LUN 大小</span><span class="sxs-lookup"><span data-stu-id="63c10-206">LUN Size</span></span>|<span data-ttu-id="63c10-207">RAID 設定</span><span class="sxs-lookup"><span data-stu-id="63c10-207">RAID configuration</span></span>|  
|------------------|-----------------|--------------|------------------------|  
|<span data-ttu-id="63c10-208">G:</span><span class="sxs-lookup"><span data-stu-id="63c10-208">G:</span></span>|<span data-ttu-id="63c10-209">Data_Sys</span><span class="sxs-lookup"><span data-stu-id="63c10-209">Data_Sys</span></span>|<span data-ttu-id="63c10-210">10</span><span class="sxs-lookup"><span data-stu-id="63c10-210">10</span></span>|<span data-ttu-id="63c10-211">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-211">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-212">H:</span><span class="sxs-lookup"><span data-stu-id="63c10-212">H:</span></span>|<span data-ttu-id="63c10-213">Logs_Sys</span><span class="sxs-lookup"><span data-stu-id="63c10-213">Logs_Sys</span></span>|<span data-ttu-id="63c10-214">10</span><span class="sxs-lookup"><span data-stu-id="63c10-214">10</span></span>|<span data-ttu-id="63c10-215">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-215">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-216">I:</span><span class="sxs-lookup"><span data-stu-id="63c10-216">I:</span></span>|<span data-ttu-id="63c10-217">Data_TempDb</span><span class="sxs-lookup"><span data-stu-id="63c10-217">Data_TempDb</span></span>|<span data-ttu-id="63c10-218">50</span><span class="sxs-lookup"><span data-stu-id="63c10-218">50</span></span>|<span data-ttu-id="63c10-219">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-219">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-220">J:</span><span class="sxs-lookup"><span data-stu-id="63c10-220">J:</span></span>|<span data-ttu-id="63c10-221">Logs_TempDb</span><span class="sxs-lookup"><span data-stu-id="63c10-221">Logs_TempDb</span></span>|<span data-ttu-id="63c10-222">50</span><span class="sxs-lookup"><span data-stu-id="63c10-222">50</span></span>|<span data-ttu-id="63c10-223">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-223">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-224">K:</span><span class="sxs-lookup"><span data-stu-id="63c10-224">K:</span></span>|<span data-ttu-id="63c10-225">Data_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="63c10-225">Data_BtsMsgBox</span></span>|<span data-ttu-id="63c10-226">300</span><span class="sxs-lookup"><span data-stu-id="63c10-226">300</span></span>|<span data-ttu-id="63c10-227">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-227">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-228">L:</span><span class="sxs-lookup"><span data-stu-id="63c10-228">L:</span></span>|<span data-ttu-id="63c10-229">Logs_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="63c10-229">Logs_BtsMsgBox</span></span>|<span data-ttu-id="63c10-230">100</span><span class="sxs-lookup"><span data-stu-id="63c10-230">100</span></span>|<span data-ttu-id="63c10-231">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-231">RAID 0 + 1</span></span>|  
|<span data-ttu-id="63c10-232">M:</span><span class="sxs-lookup"><span data-stu-id="63c10-232">M:</span></span>|<span data-ttu-id="63c10-233">MSDTC</span><span class="sxs-lookup"><span data-stu-id="63c10-233">MSDTC</span></span>|<span data-ttu-id="63c10-234">5</span><span class="sxs-lookup"><span data-stu-id="63c10-234">5</span></span>|<span data-ttu-id="63c10-235">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="63c10-235">RAID 0 + 1</span></span>|  
  
#### <a name="iometer-configuration"></a><span data-ttu-id="63c10-236">IOMeter 設定</span><span class="sxs-lookup"><span data-stu-id="63c10-236">IOMeter Configuration</span></span>  
 <span data-ttu-id="63c10-237">IOMeter 工具可用來當做基準測試和疑難排解工具藉由複寫應用程式的讀取/寫入效能。</span><span class="sxs-lookup"><span data-stu-id="63c10-237">The IOMeter tool can be used as a benchmark and troubleshooting tool by replicating the read/write performance of applications.</span></span> <span data-ttu-id="63c10-238">IOMeter 是效能的一種可設定的工具，可用來模擬各種不同。</span><span class="sxs-lookup"><span data-stu-id="63c10-238">IOMeter is a configurable tool that can be used to simulate many different types of performance.</span></span> <span data-ttu-id="63c10-239">基於此測試案例的詳細資訊，IOMeter 組態參數已設定為下表中所述，在這兩個實體[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]已經過測試的電腦和客體作業系統執行[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]在 HYPER-V 虛擬機器:</span><span class="sxs-lookup"><span data-stu-id="63c10-239">For purposes of this test scenario, IOMeter configuration parameters were set as described in the table below on both the physical [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] computer that was tested and on the guest operating system that was running [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] in a Hyper-V virtual machine:</span></span>  
  
### <a name="iometer--passthrough-disk-comparison-test-configuration"></a><span data-ttu-id="63c10-240">IOMeter – 穿通磁碟比較測試組態</span><span class="sxs-lookup"><span data-stu-id="63c10-240">IOMeter – Passthrough Disk Comparison Test Configuration</span></span>  
  
|                             |                     |
|-----------------------------|---------------------|
|       <span data-ttu-id="63c10-241">**測試時間長度**</span><span class="sxs-lookup"><span data-stu-id="63c10-241">**Test length**</span></span>       |     <span data-ttu-id="63c10-242">10 分鐘</span><span class="sxs-lookup"><span data-stu-id="63c10-242">10 minutes</span></span>      |
|      <span data-ttu-id="63c10-243">**加快時間**</span><span class="sxs-lookup"><span data-stu-id="63c10-243">**Ramp up time**</span></span>       |     <span data-ttu-id="63c10-244">30 秒</span><span class="sxs-lookup"><span data-stu-id="63c10-244">30 seconds</span></span>      |
|    <span data-ttu-id="63c10-245">**背景工作角色數目**</span><span class="sxs-lookup"><span data-stu-id="63c10-245">**Number of workers**</span></span>    |          <span data-ttu-id="63c10-246">4</span><span class="sxs-lookup"><span data-stu-id="63c10-246">4</span></span>          |
|  <span data-ttu-id="63c10-247">**傳送要求大小**</span><span class="sxs-lookup"><span data-stu-id="63c10-247">**Transfer request size**</span></span>  |        <span data-ttu-id="63c10-248">2 KB</span><span class="sxs-lookup"><span data-stu-id="63c10-248">2 KB</span></span>         |
| <span data-ttu-id="63c10-249">**讀取/寫入散發**</span><span class="sxs-lookup"><span data-stu-id="63c10-249">**Read/write distribution**</span></span> | <span data-ttu-id="63c10-250">66%的讀取，33%的寫入</span><span class="sxs-lookup"><span data-stu-id="63c10-250">66% read, 33% write</span></span> |
|      <span data-ttu-id="63c10-251">**高載長度**</span><span class="sxs-lookup"><span data-stu-id="63c10-251">**Burst length**</span></span>       |       <span data-ttu-id="63c10-252">1 個 I/o</span><span class="sxs-lookup"><span data-stu-id="63c10-252">1 I/Os</span></span>        |
|      <span data-ttu-id="63c10-253">**目標磁碟機**</span><span class="sxs-lookup"><span data-stu-id="63c10-253">**Target Drive**</span></span>       |         <span data-ttu-id="63c10-254">K:\\</span><span class="sxs-lookup"><span data-stu-id="63c10-254">K:\\</span></span>         |
  
#### <a name="test-description"></a><span data-ttu-id="63c10-255">測試描述</span><span class="sxs-lookup"><span data-stu-id="63c10-255">Test Description</span></span>  
 <span data-ttu-id="63c10-256">[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]服務已停止在這兩個伺服器，以確保 IOMeter 是唯一的程序，對磁碟執行 I/O。</span><span class="sxs-lookup"><span data-stu-id="63c10-256">The [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] service was stopped on both servers to ensure that IOMeter was the only process performing I/O against the disk.</span></span> <span data-ttu-id="63c10-257">LUN 的已使用這項測試中都位於相同的 SAN，這專用於此實驗室環境。</span><span class="sxs-lookup"><span data-stu-id="63c10-257">The LUN’s used in this test were both located on the same SAN which was dedicated to this lab environment.</span></span> <span data-ttu-id="63c10-258">不受其他 I/O 活動時執行測試，以確保結果已不扭曲針對 SAN。</span><span class="sxs-lookup"><span data-stu-id="63c10-258">No other I/O activity was performed against the SAN during the test to ensure that the results were not skewed.</span></span> <span data-ttu-id="63c10-259">然後從每個在本機執行 IOMeter 工具執行測試[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]和收集下列效能監視器計數器：</span><span class="sxs-lookup"><span data-stu-id="63c10-259">The test was then run by executing the IOMeter tool locally from each [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] and the following performance monitor counters were collected:</span></span>  
  
 <span data-ttu-id="63c10-260">**收集自 Virtual_SQL01 和 Physical_SQL01**:</span><span class="sxs-lookup"><span data-stu-id="63c10-260">**Collected from both Virtual_SQL01 and Physical_SQL01**:</span></span>  
  
- <span data-ttu-id="63c10-261">\LogicalDisk (\*)\\\*</span><span class="sxs-lookup"><span data-stu-id="63c10-261">\LogicalDisk(\*)\\\*</span></span>  
  
- <span data-ttu-id="63c10-262">\PhysicalDisk (\*)\\\*</span><span class="sxs-lookup"><span data-stu-id="63c10-262">\PhysicalDisk(\*)\\\*</span></span>  
  
  <span data-ttu-id="63c10-263">**收集自虛擬機器的 Hyper-v V_02**:</span><span class="sxs-lookup"><span data-stu-id="63c10-263">**Collected from virtual machine Hyper-V_02**:</span></span>  
  
- <span data-ttu-id="63c10-264">\\Hyper V 虛擬存放裝置\\\*</span><span class="sxs-lookup"><span data-stu-id="63c10-264">\\Hyper-V Virtual Storage Device\\\*</span></span>  
  
### <a name="results"></a><span data-ttu-id="63c10-265">結果</span><span class="sxs-lookup"><span data-stu-id="63c10-265">Results</span></span>  
 <span data-ttu-id="63c10-266">傳遞磁碟無法達到超過 90%的直接連線到 Physical_SQL01 SAN LUN 的輸送量。</span><span class="sxs-lookup"><span data-stu-id="63c10-266">The passthrough disk was able to attain over 90% of the throughput of the SAN LUN connected directly to Physical_SQL01.</span></span>  <span data-ttu-id="63c10-267">總計、 讀取和寫入一樣是每秒傳送的總 MB 每秒的 I/o 已全都可在 10%。</span><span class="sxs-lookup"><span data-stu-id="63c10-267">Total, read and write I/Os per second were all within 10% as was the total MB transferred per second.</span></span>  <span data-ttu-id="63c10-268">狀況良好的磁碟回應時間應介於 1 到 15 毫秒的讀取和寫入。</span><span class="sxs-lookup"><span data-stu-id="63c10-268">Response times for healthy disks should be between 1-15 ms for read and write.</span></span> <span data-ttu-id="63c10-269">平均 I/O 回應時間都小於 4 毫秒，這兩個磁碟上。</span><span class="sxs-lookup"><span data-stu-id="63c10-269">Average I/O response times were less than 4 ms on both disks.</span></span> <span data-ttu-id="63c10-270">隨機讀取回應時間是在實體上以及 5.7 ms 傳遞磁碟上的 5.4 毫秒。</span><span class="sxs-lookup"><span data-stu-id="63c10-270">Random reads response time was 5.4 ms on the physical and 5.7 ms on the pass-through disk.</span></span> <span data-ttu-id="63c10-271">寫入回應時間為小於 0.5 毫秒在實體和虛擬環境。</span><span class="sxs-lookup"><span data-stu-id="63c10-271">Write response time was less than 0.5 ms on both the physical and virtual environments.</span></span>  
  
 <span data-ttu-id="63c10-272">結果會指出，使用已啟用的 SCSI 控制器的傳遞磁碟可以提供超過 90%的直接連線的實體磁碟的效能。</span><span class="sxs-lookup"><span data-stu-id="63c10-272">The results indicate that a passthrough disk using the enlightened SCSI controller can provide over 90% of the performance of a directly connected physical disk.</span></span> <span data-ttu-id="63c10-273">有效的 BizTalk Server 作業的 I/O 子系統效能至關重要藉由提供極佳的輸送量和回應時間 HYPER-V 是絕佳的候選項目合併 BizTalk Server 環境。</span><span class="sxs-lookup"><span data-stu-id="63c10-273">I/O subsystem performance is critical for efficient BizTalk Server operation, by providing excellent throughput and response times Hyper-V is an excellent candidate for consolidating a BizTalk Server environment.</span></span> <span data-ttu-id="63c10-274">下表提供比較的實體磁碟的傳遞磁碟的效能時，所觀察到磁碟測試結果的摘要：</span><span class="sxs-lookup"><span data-stu-id="63c10-274">The table below provides a summary of the disk test results observed when comparing performance of a passthrough disk to a physical disk:</span></span>  
  
|<span data-ttu-id="63c10-275">度量單位</span><span class="sxs-lookup"><span data-stu-id="63c10-275">Measurement</span></span>|<span data-ttu-id="63c10-276">Physical_SQL01 （實體磁碟）</span><span class="sxs-lookup"><span data-stu-id="63c10-276">Physical_SQL01 (Physical Disk)</span></span>|<span data-ttu-id="63c10-277">Virtual_SQL01 (passthrough)</span><span class="sxs-lookup"><span data-stu-id="63c10-277">Virtual_SQL01 (passthrough)</span></span>|<span data-ttu-id="63c10-278">實體磁碟的傳遞磁碟的相對效能</span><span class="sxs-lookup"><span data-stu-id="63c10-278">Relative performance of passthrough disks to physical disks</span></span>|  
|-----------------|---------------------------------------|------------------------------------|-----------------------------------------------------------------|  
|<span data-ttu-id="63c10-279">每秒的總 I/o</span><span class="sxs-lookup"><span data-stu-id="63c10-279">Total I/Os per second</span></span>|<span data-ttu-id="63c10-280">269.73</span><span class="sxs-lookup"><span data-stu-id="63c10-280">269.73</span></span>|<span data-ttu-id="63c10-281">250.47</span><span class="sxs-lookup"><span data-stu-id="63c10-281">250.47</span></span>|<span data-ttu-id="63c10-282">92.86%</span><span class="sxs-lookup"><span data-stu-id="63c10-282">92.86%</span></span>|  
|<span data-ttu-id="63c10-283">每秒的讀取 I/o</span><span class="sxs-lookup"><span data-stu-id="63c10-283">Read I/Os per second</span></span>|<span data-ttu-id="63c10-284">180.73</span><span class="sxs-lookup"><span data-stu-id="63c10-284">180.73</span></span>|<span data-ttu-id="63c10-285">167.60</span><span class="sxs-lookup"><span data-stu-id="63c10-285">167.60</span></span>|<span data-ttu-id="63c10-286">92.74%</span><span class="sxs-lookup"><span data-stu-id="63c10-286">92.74%</span></span>|  
|<span data-ttu-id="63c10-287">每秒寫入 I/o</span><span class="sxs-lookup"><span data-stu-id="63c10-287">Write I/Os per second</span></span>|<span data-ttu-id="63c10-288">89.00</span><span class="sxs-lookup"><span data-stu-id="63c10-288">89.00</span></span>|<span data-ttu-id="63c10-289">82.87</span><span class="sxs-lookup"><span data-stu-id="63c10-289">82.87</span></span>|<span data-ttu-id="63c10-290">93.11%</span><span class="sxs-lookup"><span data-stu-id="63c10-290">93.11%</span></span>|  
|<span data-ttu-id="63c10-291">每秒的總 Mb</span><span class="sxs-lookup"><span data-stu-id="63c10-291">Total MBs per second</span></span>|<span data-ttu-id="63c10-292">0.53</span><span class="sxs-lookup"><span data-stu-id="63c10-292">0.53</span></span>|<span data-ttu-id="63c10-293">0.49</span><span class="sxs-lookup"><span data-stu-id="63c10-293">0.49</span></span>|<span data-ttu-id="63c10-294">92.45%</span><span class="sxs-lookup"><span data-stu-id="63c10-294">92.45%</span></span>|  
|<span data-ttu-id="63c10-295">平均讀取回應時間 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="63c10-295">Average read response time (ms)</span></span>|<span data-ttu-id="63c10-296">5.4066</span><span class="sxs-lookup"><span data-stu-id="63c10-296">5.4066</span></span>|<span data-ttu-id="63c10-297">5.7797</span><span class="sxs-lookup"><span data-stu-id="63c10-297">5.7797</span></span>|<span data-ttu-id="63c10-298">93.54%</span><span class="sxs-lookup"><span data-stu-id="63c10-298">93.54%</span></span>|  
|<span data-ttu-id="63c10-299">平均寫入回應時間 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="63c10-299">Average write response time (ms)</span></span>|<span data-ttu-id="63c10-300">0.2544</span><span class="sxs-lookup"><span data-stu-id="63c10-300">0.2544</span></span>|<span data-ttu-id="63c10-301">0.3716</span><span class="sxs-lookup"><span data-stu-id="63c10-301">0.3716</span></span>|<span data-ttu-id="63c10-302">68.42%**附註：** 雖然傳遞磁碟的平均寫入回應時間的相對效能皆為 68.42%的實體磁碟效能，也仍在已傳遞磁碟的平均寫入回應時間建立可接受的限制為 10 毫秒。</span><span class="sxs-lookup"><span data-stu-id="63c10-302">68.42% **Note:**  Although the relative performance of the pass through disks for Average write response time was 68.42% of the performance of physical disks, the Average write response time of the passthrough disks was still well within established acceptable limits of 10 ms.</span></span>|  
|<span data-ttu-id="63c10-303">平均 I/O 回應時間 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="63c10-303">Average I/O response time (ms)</span></span>|<span data-ttu-id="63c10-304">3.7066</span><span class="sxs-lookup"><span data-stu-id="63c10-304">3.7066</span></span>|<span data-ttu-id="63c10-305">3.9904</span><span class="sxs-lookup"><span data-stu-id="63c10-305">3.9904</span></span>|<span data-ttu-id="63c10-306">93.89%</span><span class="sxs-lookup"><span data-stu-id="63c10-306">93.89%</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="63c10-307">每秒的總 I/o、 每秒的讀取 I/o、 每秒寫入的 I/o 和每秒的總 mb/s 的百分比值已計算是將傳遞磁碟值對應的實體磁碟值。</span><span class="sxs-lookup"><span data-stu-id="63c10-307">The percentage values for Total I/Os per second, Read I/Os per second, Write I/Os per second, and Total MBs per second were calculated by dividing passthrough disk values by the corresponding physical disk values.</span></span>  
>   
>  <span data-ttu-id="63c10-308">百分比值的平均讀取回應時間 （毫秒），平均寫入回應時間 （毫秒），並除以實體磁碟值相對應的傳遞磁碟值來計算平均 I/O 回應時間 （毫秒）。</span><span class="sxs-lookup"><span data-stu-id="63c10-308">The percentage values for Average read response time (ms), Average write response time (ms), and Average I/O response time (ms) were calculated by dividing physical disk values by the corresponding passthrough disk values.</span></span>